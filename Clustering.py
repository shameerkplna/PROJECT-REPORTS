# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w80AYDmMSHOeVsk2Bem8-wW4f0UtpfK0
"""

# Load the Iris dataset from sklearn.

from sklearn import datasets
import pandas as pd

iris = datasets.load_iris()
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)

iris_df

# Drop the species column
iris_df = iris_df.drop(columns=['petal width (cm)'])

# Display the first few rows
print(iris_df.head())

# KMeans clustering is an unsupervised learning algorithm that partitions the data into K clusters.
# Each cluster is represented by its centroid, which is the mean of the points in the cluster.
# The algorithm iteratively assigns each point to the nearest centroid and then updates the centroids based on the new assignments.

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# KMeans clustering
kmeans = KMeans(n_clusters=3, random_state=42)
iris_df['kmeans_cluster'] = kmeans.fit_predict(iris_df)

# Visualize the clusters
plt.scatter(iris_df.iloc[:, 0], iris_df.iloc[:, 1], c=iris_df['kmeans_cluster'], cmap='viridis')
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.title('KMeans Clustering of Iris Dataset')
plt.show()

#Hierarchical clustering builds a hierarchy of clusters by either merging smaller clusters into larger ones (agglomerative) or splitting larger clusters into smaller ones (divisive).
#The result is a tree-like structure called a dendrogram.

from scipy.cluster.hierarchy import dendrogram, linkage

# Apply Hierarchical clustering
linked = linkage(iris_df, method='ward')

# Visualize the clusters
plt.figure(figsize=(10, 7))
dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)
plt.title('Hierarchical Clustering Dendrogram')
plt.show()